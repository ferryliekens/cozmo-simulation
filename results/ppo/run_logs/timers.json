{
    "name": "root",
    "gauges": {
        "HoldBallBehaviour.Policy.Entropy.mean": {
            "value": 1.4284566640853882,
            "min": 1.4167124032974243,
            "max": 1.430437445640564,
            "count": 54
        },
        "HoldBallBehaviour.Policy.Entropy.sum": {
            "value": 71582.8203125,
            "min": 70912.203125,
            "max": 71788.515625,
            "count": 54
        },
        "HoldBallBehaviour.Policy.ExtrinsicValueEstimate.mean": {
            "value": -87.42562103271484,
            "min": -89.4089584350586,
            "max": 4.134899139404297,
            "count": 54
        },
        "HoldBallBehaviour.Policy.ExtrinsicValueEstimate.sum": {
            "value": -353986.34375,
            "min": -353986.34375,
            "max": 6045.22265625,
            "count": 54
        },
        "HoldBallBehaviour.Environment.EpisodeLength.mean": {
            "value": 12.110615989515072,
            "min": 12.110615989515072,
            "max": 64.3399209486166,
            "count": 54
        },
        "HoldBallBehaviour.Environment.EpisodeLength.sum": {
            "value": 46202.0,
            "min": 46202.0,
            "max": 49415.0,
            "count": 54
        },
        "HoldBallBehaviour.Environment.CumulativeReward.mean": {
            "value": -50590.72555701179,
            "min": -50590.72555701179,
            "max": 7.644329896907217,
            "count": 54
        },
        "HoldBallBehaviour.Environment.CumulativeReward.sum": {
            "value": -193003618.0,
            "min": -193003618.0,
            "max": 7415.0,
            "count": 54
        },
        "HoldBallBehaviour.Policy.ExtrinsicReward.mean": {
            "value": -50590.72555701179,
            "min": -50590.72555701179,
            "max": 7.644329896907217,
            "count": 54
        },
        "HoldBallBehaviour.Policy.ExtrinsicReward.sum": {
            "value": -193003618.0,
            "min": -193003618.0,
            "max": 7415.0,
            "count": 54
        },
        "HoldBallBehaviour.Losses.PolicyLoss.mean": {
            "value": 0.02422940509393811,
            "min": 0.02133146448836972,
            "max": 0.025313899191096424,
            "count": 10
        },
        "HoldBallBehaviour.Losses.PolicyLoss.sum": {
            "value": 0.12114702546969056,
            "min": 0.09264520124221842,
            "max": 0.12656949595548211,
            "count": 10
        },
        "HoldBallBehaviour.Losses.ValueLoss.mean": {
            "value": 1060.9723767089843,
            "min": 3.524205525716146,
            "max": 1060.9723767089843,
            "count": 10
        },
        "HoldBallBehaviour.Losses.ValueLoss.sum": {
            "value": 5304.8618835449215,
            "min": 14.096822102864584,
            "max": 5304.8618835449215,
            "count": 10
        },
        "HoldBallBehaviour.Policy.LearningRate.mean": {
            "value": 1.6279174573640006e-05,
            "min": 1.6279174573640006e-05,
            "max": 0.00028455540514819996,
            "count": 10
        },
        "HoldBallBehaviour.Policy.LearningRate.sum": {
            "value": 8.139587286820003e-05,
            "min": 8.139587286820003e-05,
            "max": 0.0012840516719827997,
            "count": 10
        },
        "HoldBallBehaviour.Policy.Epsilon.mean": {
            "value": 0.10542636000000002,
            "min": 0.10542636000000002,
            "max": 0.19485180000000002,
            "count": 10
        },
        "HoldBallBehaviour.Policy.Epsilon.sum": {
            "value": 0.5271318000000002,
            "min": 0.4998424000000001,
            "max": 0.9280172000000001,
            "count": 10
        },
        "HoldBallBehaviour.Policy.Beta.mean": {
            "value": 0.0002807753640000002,
            "min": 0.0002807753640000002,
            "max": 0.00474310482,
            "count": 10
        },
        "HoldBallBehaviour.Policy.Beta.sum": {
            "value": 0.001403876820000001,
            "min": 0.001403876820000001,
            "max": 0.021408058280000003,
            "count": 10
        },
        "HoldBallBehaviour.IsTraining.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 54
        },
        "HoldBallBehaviour.IsTraining.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 1.0,
            "count": 54
        },
        "HoldBall.Policy.Entropy.mean": {
            "value": 1.4184176921844482,
            "min": 1.4171808958053589,
            "max": 1.4184176921844482,
            "count": 2
        },
        "HoldBall.Policy.Entropy.sum": {
            "value": 70884.0078125,
            "min": 70884.0078125,
            "max": 70908.6484375,
            "count": 2
        },
        "HoldBall.Policy.ExtrinsicValueEstimate.mean": {
            "value": -128.4945526123047,
            "min": -128.4945526123047,
            "max": -5.707347393035889,
            "count": 2
        },
        "HoldBall.Policy.ExtrinsicValueEstimate.sum": {
            "value": -195954.1875,
            "min": -195954.1875,
            "max": -9902.248046875,
            "count": 2
        },
        "HoldBall.Environment.EpisodeLength.mean": {
            "value": 31.92094861660079,
            "min": 31.239046391752577,
            "max": 31.92094861660079,
            "count": 2
        },
        "HoldBall.Environment.EpisodeLength.sum": {
            "value": 48456.0,
            "min": 48456.0,
            "max": 48483.0,
            "count": 2
        },
        "HoldBall.Environment.CumulativeReward.mean": {
            "value": -1043.6706192358367,
            "min": -1043.6706192358367,
            "max": -168.68214055448098,
            "count": 2
        },
        "HoldBall.Environment.CumulativeReward.sum": {
            "value": -1584292.0,
            "min": -1584292.0,
            "max": -261626.0,
            "count": 2
        },
        "HoldBall.Policy.ExtrinsicReward.mean": {
            "value": -1043.6706192358367,
            "min": -1043.6706192358367,
            "max": -168.68214055448098,
            "count": 2
        },
        "HoldBall.Policy.ExtrinsicReward.sum": {
            "value": -1584292.0,
            "min": -1584292.0,
            "max": -261626.0,
            "count": 2
        },
        "HoldBall.Losses.PolicyLoss.mean": {
            "value": 0.021761975750947994,
            "min": 0.021761975750947994,
            "max": 0.022732421534601595,
            "count": 2
        },
        "HoldBall.Losses.PolicyLoss.sum": {
            "value": 0.10880987875473996,
            "min": 0.09092968613840638,
            "max": 0.10880987875473996,
            "count": 2
        },
        "HoldBall.Losses.ValueLoss.mean": {
            "value": 155865.68615885417,
            "min": 9840.11586373647,
            "max": 155865.68615885417,
            "count": 2
        },
        "HoldBall.Losses.ValueLoss.sum": {
            "value": 779328.4307942708,
            "min": 39360.46345494588,
            "max": 779328.4307942708,
            "count": 2
        },
        "HoldBall.Policy.LearningRate.mean": {
            "value": 0.00025688809437064003,
            "min": 0.00025688809437064003,
            "max": 0.00028460625513124997,
            "count": 2
        },
        "HoldBall.Policy.LearningRate.sum": {
            "value": 0.0012844404718532001,
            "min": 0.0011384250205249999,
            "max": 0.0012844404718532001,
            "count": 2
        },
        "HoldBall.Policy.Epsilon.mean": {
            "value": 0.18562936,
            "min": 0.18562936,
            "max": 0.19486875,
            "count": 2
        },
        "HoldBall.Policy.Epsilon.sum": {
            "value": 0.9281467999999999,
            "min": 0.779475,
            "max": 0.9281467999999999,
            "count": 2
        },
        "HoldBall.Policy.Beta.mean": {
            "value": 0.004282905064000001,
            "min": 0.004282905064000001,
            "max": 0.004743950625000001,
            "count": 2
        },
        "HoldBall.Policy.Beta.sum": {
            "value": 0.021414525320000002,
            "min": 0.018975802500000003,
            "max": 0.021414525320000002,
            "count": 2
        },
        "HoldBall.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 2
        },
        "HoldBall.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 2
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1624809188",
        "python_version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]",
        "command_line_arguments": "D:\\Productivity\\Projects\\unityProjects\\Cozmo simulation\\venv\\Scripts\\mlagents-learn --force",
        "mlagents_version": "0.25.0",
        "mlagents_envs_version": "0.25.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.0+cu110",
        "numpy_version": "1.20.2",
        "end_time_seconds": "1624813074"
    },
    "total": 3886.2675482,
    "count": 1,
    "self": 0.05301129999998011,
    "children": {
        "run_training.setup": {
            "total": 0.024330300000000138,
            "count": 1,
            "self": 0.024330300000000138
        },
        "TrainerController.start_learning": {
            "total": 3886.1902066,
            "count": 1,
            "self": 4.43873059991347,
            "children": {
                "TrainerController._reset_env": {
                    "total": 11.274780400000001,
                    "count": 1,
                    "self": 11.274780400000001
                },
                "TrainerController.advance": {
                    "total": 3870.2358359000864,
                    "count": 192045,
                    "self": 2.042848900118315,
                    "children": {
                        "env_step": {
                            "total": 3868.192986999968,
                            "count": 192045,
                            "self": 3485.5472913998706,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 380.5050515000552,
                                    "count": 192045,
                                    "self": 13.302971499943965,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 367.2020800001112,
                                            "count": 226852,
                                            "self": 139.36400540010288,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 227.83807460000833,
                                                    "count": 226852,
                                                    "self": 227.83807460000833
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 2.1406441000421577,
                                    "count": 192044,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 3871.0976889000726,
                                            "count": 192044,
                                            "is_parallel": true,
                                            "self": 648.0812082000175,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0005332999999989596,
                                                    "count": 2,
                                                    "is_parallel": true,
                                                    "self": 0.00022249999999957026,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00031079999999938934,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.00031079999999938934
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 3223.015947400055,
                                                    "count": 192044,
                                                    "is_parallel": true,
                                                    "self": 17.016343899973435,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 94.05408930001343,
                                                            "count": 192044,
                                                            "is_parallel": true,
                                                            "self": 94.05408930001343
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 3053.555613000041,
                                                            "count": 192044,
                                                            "is_parallel": true,
                                                            "self": 3053.555613000041
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 58.38990120002756,
                                                            "count": 384088,
                                                            "is_parallel": true,
                                                            "self": 29.32493390009573,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 29.06496729993183,
                                                                    "count": 768176,
                                                                    "is_parallel": true,
                                                                    "self": 29.06496729993183
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 3.2500000088475645e-05,
                    "count": 1,
                    "self": 3.2500000088475645e-05,
                    "children": {
                        "thread_root": {
                            "total": 0.0,
                            "count": 0,
                            "is_parallel": true,
                            "self": 0.0,
                            "children": {
                                "trainer_advance": {
                                    "total": 7741.716109399915,
                                    "count": 592613,
                                    "is_parallel": true,
                                    "self": 22.783965299796364,
                                    "children": {
                                        "process_trajectory": {
                                            "total": 7605.269007200119,
                                            "count": 592613,
                                            "is_parallel": true,
                                            "self": 7604.984625300119,
                                            "children": {
                                                "RLTrainer._checkpoint": {
                                                    "total": 0.28438189999974384,
                                                    "count": 5,
                                                    "is_parallel": true,
                                                    "self": 0.28438189999974384
                                                }
                                            }
                                        },
                                        "_update_policy": {
                                            "total": 113.66313689999981,
                                            "count": 59,
                                            "is_parallel": true,
                                            "self": 78.50661339999739,
                                            "children": {
                                                "TorchPPOOptimizer.update": {
                                                    "total": 35.15652350000242,
                                                    "count": 1770,
                                                    "is_parallel": true,
                                                    "self": 35.15652350000242
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.24082719999978508,
                    "count": 1,
                    "self": 0.028563100000155828,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.21226409999962925,
                            "count": 2,
                            "self": 0.21226409999962925
                        }
                    }
                }
            }
        }
    }
}